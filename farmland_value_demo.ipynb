{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook simulates data for a hypothetical farmland appraisal modeling task. We look in particular at the different model fits during k-fold cross-validation, the estimate of generalization error produced by cross-validation, and the confidence interval for the generalization error.\n",
    "\n",
    "This notebook produces figures published in The Crosstab Kite's article [Research Digest: What does cross-validation really estimate?](https://crosstab.io/articles/bates-cross-validation), which digests the research paper [Cross-validation: what does it estimate and how well does it do it?](https://arxiv.org/abs/2104.00673) by Bates, Hastie, and Tibshirani.\n",
    "\n",
    "The plot styling is intended for the figures as they appear in the article, so they look really bad in this notebook. That's known and ok."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.offline as pyo\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "pyo.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generic plot style\n",
    "baseline_style = dict(\n",
    "    font=dict(family=\"Arial\", size=36),\n",
    "    template=\"simple_white\",\n",
    ")\n",
    "\n",
    "marker_size = 26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The true regression function of sale price is quadratic in property acreage. The distribution of acreage and sale prices is intended to very loosely mimic agricultural property values in the Hill Country of Texas, based on [data from Texas A&M](https://www.recenter.tamu.edu/data/rural-land/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(18)\n",
    "\n",
    "n = 100\n",
    "\n",
    "acreage_mean = 120\n",
    "acreage_sd = 30\n",
    "\n",
    "price_sd = 350000\n",
    "target = \"price\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"acres\": np.random.normal(acreage_mean, acreage_sd, n)})\n",
    "\n",
    "noise = np.random.normal(loc=0, scale=price_sd, size=n)\n",
    "df[\"sq_acres\"] = df[\"acres\"] ** 2\n",
    "df[target] = 2000 * df[\"acres\"] + 50 * df[\"sq_acres\"] + noise\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df[\"acres\"],\n",
    "        y=df[\"price\"],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(\n",
    "            symbol=\"circle\",\n",
    "            color=\"rgba(100, 149, 237, 0.35)\",\n",
    "            size=marker_size,\n",
    "            line=dict(width=2, color=\"#15388d\"),\n",
    "        ),\n",
    "        showlegend=False,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(baseline_style)\n",
    "fig.update_layout(xaxis_title=\"Acres\", yaxis_title=\"Sale price ($)\")\n",
    "fig.write_image(\"sim_farm_sales.png\", height=1400, width=1400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a grid of values for the `acres` features, for plotting quadratic model fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgrid = pd.DataFrame(\n",
    "    {\"acres\": np.linspace(df[\"acres\"].min() - 5, df[\"acres\"].max() + 5, 100)}\n",
    ")\n",
    "xgrid[\"sq_acres\"] = xgrid[\"acres\"] ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Select the best model form with 5-fold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn has a convenience function [`cross_val_score`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score) that makes this a lot less verbose. Here we use the `KFold` iterator to show the steps more carefully and to more closely match the Bates, et al. paper. Specifically, the Bates, et al. paper computes the cross-validation error a little differently than most. Most sources say to take the average of the per-fold test errors, but Bates et al. record then error for each point when it's in the test, then take the average of all points at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_errors = np.array([])\n",
    "quad_errors = np.array([])\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "for ix_train, ix_test in kfold.split(df):\n",
    "\n",
    "    # Split data\n",
    "    df_train = df.loc[ix_train]\n",
    "    df_test = df.loc[ix_test]\n",
    "\n",
    "    # Fit the linear model and get test RMSE\n",
    "    linear_model = LinearRegression()\n",
    "    linear_model.fit(df_train[[\"acres\"]], df_train[[target]])\n",
    "    linear_ystar = linear_model.predict(df_test[[\"acres\"]]).flatten()\n",
    "    linear_errors = np.append(linear_errors, (df_test[target] - linear_ystar))\n",
    "\n",
    "    # Draw the trained linear model on the plot.\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=xgrid[\"acres\"],\n",
    "            y=linear_model.predict(xgrid[[\"acres\"]]).flatten(),\n",
    "            mode=\"lines\",\n",
    "            line=dict(width=3, dash=\"dash\", color=\"orange\"),\n",
    "            showlegend=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Fit the quadratic model and get test RMSE\n",
    "    quad_model = LinearRegression()\n",
    "    quad_model.fit(df_train[[\"acres\", \"sq_acres\"]], df_train[target])\n",
    "    quad_ystar = quad_model.predict(df_test[[\"acres\", \"sq_acres\"]]).flatten()\n",
    "    quad_errors = np.append(quad_errors, (df_test[target] - quad_ystar))\n",
    "\n",
    "    # Draw the trained quadratic model on the plot.\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=xgrid[\"acres\"],\n",
    "            y=quad_model.predict(xgrid[[\"acres\", \"sq_acres\"]]).flatten(),\n",
    "            mode=\"lines\",\n",
    "            line=dict(width=3, dash=\"dash\", color=\"purple\"),\n",
    "            showlegend=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "linear_cv_rmse = (linear_errors ** 2).mean() ** 0.5\n",
    "quad_cv_rmse = (quad_errors ** 2).mean() ** 0.5\n",
    "\n",
    "print(f\"{linear_cv_rmse=}\")\n",
    "print(f\"{quad_cv_rmse=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, given that the true regression function is quadratic, the quadratic form has lower cross-validation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig.add_annotation(\n",
    "    x=205,\n",
    "    y=1.65e6,\n",
    "    text=f\"Linear model<br>5-fold CV fits<br>CV RMSE: ${linear_cv_rmse:,.2f}\",\n",
    "    showarrow=False,\n",
    "    font=dict(color=\"orange\"),\n",
    ")\n",
    "\n",
    "fig.add_annotation(\n",
    "    x=150,\n",
    "    y=2.8e6,\n",
    "    text=f\"Quadratic model<br>5-fold CV fits<br>CV RMSE: ${quad_cv_rmse:,.2f}\",\n",
    "    showarrow=False,\n",
    "    font=dict(color=\"purple\"),\n",
    ")\n",
    "\n",
    "fig.write_image(\"cv_model_fits.png\", height=1400, width=1400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Re-fit best predictive model to the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = LinearRegression()\n",
    "final_model.fit(df[[\"acres\", \"sq_acres\"]], df[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Illustrate generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we really care about is the model's generalization error, which is the average model prediction error (measured by our squared error loss function) on new data points from the same distribution. Here we just manually create two new data points for the purpose of illustration on our schematic plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame({\"acres\": [90, 170]})\n",
    "df_new[\"sq_acres\"] = df_new[\"acres\"] ** 2\n",
    "df_new[\"ystar\"] = final_model.predict(df_new[[\"acres\", \"sq_acres\"]])\n",
    "df_new[\"price\"] = [5.8e5, 1.1e6]\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the final model with the new points and the model's predictions for those points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df[\"acres\"],\n",
    "        y=df[\"price\"],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(\n",
    "            symbol=\"circle\",\n",
    "            color=\"rgba(100, 149, 237, 0.35)\",\n",
    "            size=marker_size,\n",
    "            line=dict(width=2, color=\"#15388d\"),\n",
    "        ),\n",
    "        showlegend=False,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        name=\"Final model\",\n",
    "        x=xgrid[\"acres\"],\n",
    "        y=final_model.predict(xgrid[[\"acres\", \"sq_acres\"]]).flatten(),\n",
    "        mode=\"lines\",\n",
    "        line=dict(width=6, color=\"purple\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        name=\"New point true values (unknown)\",\n",
    "        x=df_new[\"acres\"],\n",
    "        y=df_new[\"price\"],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(\n",
    "            symbol=\"circle-open\", color=\"red\", size=marker_size + 4, line_width=4\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        name=\"New point predictions\",\n",
    "        x=df_new[\"acres\"],\n",
    "        y=df_new[\"ystar\"],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(symbol=\"x\", color=\"red\", size=marker_size + 4),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_annotation(\n",
    "    x=200,\n",
    "    y=6.8e5,\n",
    "    text=\"Averge RMSE<br>for new points: ?\",\n",
    "    showarrow=False,\n",
    "    font=dict(color=\"red\"),\n",
    ")\n",
    "\n",
    "fig.update_layout(baseline_style)\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Acres\", yaxis_title=\"Sale price ($)\", legend=dict(x=0.1, y=0.9)\n",
    ")\n",
    "\n",
    "fig.write_image(\"final_model.png\", height=1400, width=1400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naïve standard error and confidence interval of generalization error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what Bates, et al. call the *naïve cross-validation interval*. As they show, this is not a good idea - the interval is too narrow to cover the true generalization error with the intended frequency.\n",
    "\n",
    "Note that even though our loss function is squared error, we take the square root here to get RMSE for interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance = 0.1\n",
    "tail_prob = 1 - significance / 2\n",
    "z_quantile = stats.norm.ppf(tail_prob)\n",
    "print(f\"{z_quantile=}\")  # just write the value explicitly in the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_err = (quad_errors ** 2).std(ddof=1) / np.sqrt(n)\n",
    "\n",
    "avg_loss = quad_cv_rmse ** 2\n",
    "rmse_ci_lower = (avg_loss - z_quantile * std_err) ** 0.5\n",
    "rmse_ci_upper = (avg_loss + z_quantile * std_err) ** 0.5\n",
    "\n",
    "print(f\"{quad_cv_rmse=}\")\n",
    "print(f\"{rmse_ci_lower=}\")\n",
    "print(f\"{rmse_ci_upper=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a suprisingly high 90% confidence interval for generalization error. Crazy to think that it's not even wide enough to actually cover with 90% frequency."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('complete3.8': conda)",
   "language": "python",
   "name": "python38364bitcomplete38conda6b4851e4606c45b69c6094ba1f069d7d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "metadata": {
   "interpreter": {
    "hash": "9a976e94fa7bfab0a6704bf36df45769b3cf573a67615bd27b690e7be01e42ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
